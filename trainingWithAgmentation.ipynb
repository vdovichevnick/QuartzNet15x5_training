{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import nemo\n",
    "import nemo.collections.asr as nemo_asr\n",
    "import pytorch_lightning as pl\n",
    "from ruamel.yaml import YAML\n",
    "from omegaconf import DictConfig\n",
    "from nemo.core.classes import ModelPT\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml = YAML(typ='safe')\n",
    "params_path = r\"C:\\Users\\vdovichev\\Documents\\VKR\\models_and_configs\\augmentationConf.yaml\"\n",
    "with open(params_path, encoding=\"utf-8\") as f:\n",
    "    params = yaml.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-06-12 16:41:06 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath:\n",
      "    - /home/jupyter/datasphere/datasets/RuDevices/RuDevicesDataset/manifestRuDevices.jsonl\n",
      "    - /home/jupyter/datasphere/datasets/STTandCustomer/OpenSTTruDatasets/asr_calls_2_val/manifestSTTcalls.jsonl\n",
      "    - /home/jupyter/datasphere/datasets/STTandCustomer/OpenSTTruDatasets/buriy_audiobooks_2_val/manifestSTTaudiobooks.jsonl\n",
      "    - /home/jupyter/datasphere/datasets/STTandCustomer/OpenSTTruDatasets/public_youtube700_val/manifestSTTyoutube.jsonl\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - ' '\n",
      "    - а\n",
      "    - б\n",
      "    - в\n",
      "    - г\n",
      "    - д\n",
      "    - е\n",
      "    - ж\n",
      "    - з\n",
      "    - и\n",
      "    - й\n",
      "    - к\n",
      "    - л\n",
      "    - м\n",
      "    - н\n",
      "    - о\n",
      "    - п\n",
      "    - р\n",
      "    - с\n",
      "    - т\n",
      "    - у\n",
      "    - ф\n",
      "    - х\n",
      "    - ц\n",
      "    - ч\n",
      "    - ш\n",
      "    - щ\n",
      "    - ъ\n",
      "    - ы\n",
      "    - ь\n",
      "    - э\n",
      "    - ю\n",
      "    - я\n",
      "    batch_size: 32\n",
      "    trim_silence: false\n",
      "    max_duration: 20.0\n",
      "    min_duration: 0.1\n",
      "    num_workers: 8\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    parser: ru\n",
      "    \n",
      "[NeMo W 2024-06-12 16:41:06 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    name: long_audio\n",
      "    manifest_filepath: /home/jupyter/datasphere/datasets/STTandCustomer/ValidationFromCustomer/manifestValidationFromCustomer.jsonl\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - ' '\n",
      "    - а\n",
      "    - б\n",
      "    - в\n",
      "    - г\n",
      "    - д\n",
      "    - е\n",
      "    - ж\n",
      "    - з\n",
      "    - и\n",
      "    - й\n",
      "    - к\n",
      "    - л\n",
      "    - м\n",
      "    - н\n",
      "    - о\n",
      "    - п\n",
      "    - р\n",
      "    - с\n",
      "    - т\n",
      "    - у\n",
      "    - ф\n",
      "    - х\n",
      "    - ц\n",
      "    - ч\n",
      "    - ш\n",
      "    - щ\n",
      "    - ъ\n",
      "    - ы\n",
      "    - ь\n",
      "    - э\n",
      "    - ю\n",
      "    - я\n",
      "    batch_size: 3\n",
      "    num_workers: 8\n",
      "    shuffle: false\n",
      "    parser: ru\n",
      "    \n",
      "[NeMo W 2024-06-12 16:41:06 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: test/mcv/test_ru.jsonl\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - ' '\n",
      "    - а\n",
      "    - б\n",
      "    - в\n",
      "    - г\n",
      "    - д\n",
      "    - е\n",
      "    - ж\n",
      "    - з\n",
      "    - и\n",
      "    - й\n",
      "    - к\n",
      "    - л\n",
      "    - м\n",
      "    - н\n",
      "    - о\n",
      "    - п\n",
      "    - р\n",
      "    - с\n",
      "    - т\n",
      "    - у\n",
      "    - ф\n",
      "    - х\n",
      "    - ц\n",
      "    - ч\n",
      "    - ш\n",
      "    - щ\n",
      "    - ъ\n",
      "    - ы\n",
      "    - ь\n",
      "    - э\n",
      "    - ю\n",
      "    - я\n",
      "    batch_size: 64\n",
      "    shuffle: false\n",
      "    parser: ru\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-06-12 16:41:06 features:289] PADDING: 16\n",
      "[NeMo I 2024-06-12 16:41:07 save_restore_connector:249] Model EncDecCTCModel was successfully restored from C:\\Users\\vdovichev\\Documents\\VKR\\models_and_configs\\bestQuartz1206.nemo.\n"
     ]
    }
   ],
   "source": [
    "asr_model = ModelPT.restore_from(r\"C:\\Users\\vdovichev\\Documents\\VKR\\models_and_configs\\bestQuartz1206.nemo\")\n",
    "# asr_model = nemo_asr.models.EncDecCTCModel.load_from_checkpoint(r\"C:\\Users\\vdovichev\\Documents\\FineTune\\models_configs\\wer=0.3511.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-06-12 16:42:48 modelPT:617] Trainer wasn't specified in model constructor. Make sure that you really wanted it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-06-12 16:42:48 modelPT:728] Optimizer config = Novograd (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.9, 0.98]\n",
      "        eps: 1e-08\n",
      "        grad_averaging: False\n",
      "        lr: 0.005\n",
      "        weight_decay: 0.001\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-06-12 16:42:48 lr_scheduler:890] Neither `max_steps` nor `iters_per_batch` were provided to `optim.sched`, cannot compute effective `max_steps` !\n",
      "    Scheduler will not be instantiated !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-06-12 16:42:49 collections:196] Dataset loaded with 2050 files totalling 1.83 hours\n",
      "[NeMo I 2024-06-12 16:42:49 collections:197] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo I 2024-06-12 16:42:49 collections:196] Dataset loaded with 1100 files totalling 0.33 hours\n",
      "[NeMo I 2024-06-12 16:42:49 collections:197] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo I 2024-06-12 16:42:49 collections:196] Dataset loaded with 843 files totalling 2.33 hours\n",
      "[NeMo I 2024-06-12 16:42:49 collections:197] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo I 2024-06-12 16:42:58 collections:196] Dataset loaded with 119304 files totalling 109.23 hours\n",
      "[NeMo I 2024-06-12 16:42:58 collections:197] 1 files were filtered totalling 0.01 hours\n"
     ]
    }
   ],
   "source": [
    "asr_model.setup_optimization(optim_config= DictConfig(params['optim']))\n",
    "asr_model.setup_validation_data(val_data_config=params['validation_ds'])\n",
    "asr_model.setup_training_data(train_data_config=params['train_ds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample_rate': 16000, 'repeat': 5, 'dropout': 0.0, 'separable': True, 'labels': [' ', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я'], 'optim': {'name': 'novograd', 'lr': 0.005, 'betas': [0.9, 0.98], 'weight_decay': 0.001, 'sched': {'name': 'CosineAnnealing', 'warmup_steps': 10000, 'warmup_ratio': None, 'min_lr': 0.0005, 'last_epoch': -1}}, 'train_ds': {'manifest_filepath': ['C:\\\\Users\\\\vdovichev\\\\Documents\\\\proj1-STT\\\\DatasetForFineTune\\\\RuDevicesDataset\\\\manifestRuDevices.jsonl', 'C:\\\\Users\\\\vdovichev\\\\Documents\\\\proj1-STT\\\\DatasetForFineTune\\\\OpenSTTruDatasets\\\\asr_calls_2_val\\\\manifestSTTcalls.jsonl', 'C:\\\\Users\\\\vdovichev\\\\Documents\\\\proj1-STT\\\\DatasetForFineTune\\\\OpenSTTruDatasets\\\\buriy_audiobooks_2_val\\\\manifestSTTaudiobooks.jsonl', 'C:\\\\Users\\\\vdovichev\\\\Documents\\\\proj1-STT\\\\DatasetForFineTune\\\\OpenSTTruDatasets\\\\public_youtube700_val\\\\manifestSTTyoutube.jsonl'], 'sample_rate': 16000, 'labels': [' ', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я'], 'batch_size': 16, 'trim_silence': False, 'max_duration': 20.0, 'min_duration': 0.1, 'num_workers': 8, 'shuffle': True, 'is_tarred': False, 'tarred_audio_filepaths': None, 'tarred_shard_strategy': 'scatter', 'parser': 'ru', 'augmentor': {'rir_noise_aug': {'prob': 1.0, 'rir_manifest_path': ['C:\\\\Users\\\\vdovichev\\\\Documents\\\\proj1-STT\\\\DatasetForFineTune\\\\SimulatedRIRSnoises\\\\manifestRirs.jsonl'], 'rir_prob': 0.6, 'bg_noise_manifest_paths': ['C:\\\\Users\\\\vdovichev\\\\Documents\\\\proj1-STT\\\\DatasetForFineTune\\\\PointSourceNoises\\\\manifestNoises.jsonl'], 'bg_noise_tar_filepaths': [None], 'bg_noise_prob': 0.6, 'bg_min_snr_db': [-3], 'bg_max_snr_db': [25], 'apply_noise_rir': True}}}, 'validation_ds': {'name': 'long_audio', 'manifest_filepath': ['C:\\\\Users\\\\vdovichev\\\\Documents\\\\proj1-STT\\\\DatasetForFineTune\\\\RuDevicesDataset\\\\manifestValidationRuDevices.jsonl', 'C:\\\\Users\\\\vdovichev\\\\Documents\\\\proj1-STT\\\\DatasetForFineTune\\\\OpenSTTruDatasets\\\\asr_calls_2_val\\\\manifestValidationSTTcalls.jsonl', 'C:\\\\Users\\\\vdovichev\\\\Documents\\\\proj1-STT\\\\DatasetForFineTune\\\\OpenSTTruDatasets\\\\buriy_audiobooks_2_val\\\\manifestValidationSTTaudiobooks.jsonl', 'C:\\\\Users\\\\vdovichev\\\\Documents\\\\proj1-STT\\\\DatasetForFineTune\\\\OpenSTTruDatasets\\\\public_youtube700_val\\\\manifestValidationSTTyoutube.jsonl'], 'sample_rate': 16000, 'labels': [' ', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я'], 'batch_size': 3, 'num_workers': 8, 'shuffle': False, 'parser': 'ru'}, 'test_ds': {'manifest_filepath': 'test/mcv/test_ru.jsonl', 'sample_rate': 16000, 'labels': [' ', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я'], 'batch_size': 64, 'shuffle': False, 'parser': 'ru'}, 'preprocessor': {'_target_': 'nemo.collections.asr.modules.AudioToMelSpectrogramPreprocessor', 'normalize': 'per_feature', 'window_size': 0.02, 'sample_rate': 16000, 'window_stride': 0.01, 'window': 'hann', 'features': 64, 'n_fft': 512, 'frame_splicing': 1, 'dither': 1e-05, 'stft_conv': False}, 'spec_augment': {'_target_': 'nemo.collections.asr.modules.SpectrogramAugmentation', 'rect_freq': 50, 'rect_masks': 5, 'rect_time': 120}, 'encoder': {'_target_': 'nemo.collections.asr.modules.ConvASREncoder', 'feat_in': 64, 'activation': 'relu', 'conv_mask': True, 'jasper': [{'dilation': [1], 'dropout': 0.0, 'filters': 256, 'kernel': [33], 'repeat': 1, 'residual': False, 'separable': True, 'stride': [2]}, {'dilation': [1], 'dropout': 0.0, 'filters': 256, 'kernel': [33], 'repeat': 5, 'residual': True, 'separable': True, 'stride': [1]}, {'dilation': [1], 'dropout': 0.0, 'filters': 256, 'kernel': [33], 'repeat': 5, 'residual': True, 'separable': True, 'stride': [1]}, {'dilation': [1], 'dropout': 0.0, 'filters': 256, 'kernel': [33], 'repeat': 5, 'residual': True, 'separable': True, 'stride': [1]}, {'dilation': [1], 'dropout': 0.0, 'filters': 256, 'kernel': [39], 'repeat': 5, 'residual': True, 'separable': True, 'stride': [1]}, {'dilation': [1], 'dropout': 0.0, 'filters': 256, 'kernel': [39], 'repeat': 5, 'residual': True, 'separable': True, 'stride': [1]}, {'dilation': [1], 'dropout': 0.0, 'filters': 256, 'kernel': [39], 'repeat': 5, 'residual': True, 'separable': True, 'stride': [1]}, {'dilation': [1], 'dropout': 0.0, 'filters': 512, 'kernel': [51], 'repeat': 5, 'residual': True, 'separable': True, 'stride': [1]}, {'dilation': [1], 'dropout': 0.0, 'filters': 512, 'kernel': [51], 'repeat': 5, 'residual': True, 'separable': True, 'stride': [1]}, {'dilation': [1], 'dropout': 0.0, 'filters': 512, 'kernel': [51], 'repeat': 5, 'residual': True, 'separable': True, 'stride': [1]}, {'dilation': [1], 'dropout': 0.0, 'filters': 512, 'kernel': [63], 'repeat': 5, 'residual': True, 'separable': True, 'stride': [1]}, {'dilation': [1], 'dropout': 0.0, 'filters': 512, 'kernel': [63], 'repeat': 5, 'residual': True, 'separable': True, 'stride': [1]}, {'dilation': [1], 'dropout': 0.0, 'filters': 512, 'kernel': [63], 'repeat': 5, 'residual': True, 'separable': True, 'stride': [1]}, {'dilation': [1], 'dropout': 0.0, 'filters': 512, 'kernel': [75], 'repeat': 5, 'residual': True, 'separable': True, 'stride': [1]}, {'dilation': [1], 'dropout': 0.0, 'filters': 512, 'kernel': [75], 'repeat': 5, 'residual': True, 'separable': True, 'stride': [1]}, {'dilation': [1], 'dropout': 0.0, 'filters': 512, 'kernel': [75], 'repeat': 5, 'residual': True, 'separable': True, 'stride': [1]}, {'dilation': [2], 'dropout': 0.0, 'filters': 512, 'kernel': [87], 'repeat': 1, 'residual': False, 'separable': True, 'stride': [1]}, {'dilation': [1], 'dropout': 0.0, 'filters': 1024, 'kernel': [1], 'repeat': 1, 'residual': False, 'stride': [1]}]}, 'decoder': {'_target_': 'nemo.collections.asr.modules.ConvASRDecoder', 'feat_in': 1024, 'num_classes': 33, 'vocabulary': [' ', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я']}, 'target': 'nemo.collections.asr.models.ctc_models.EncDecCTCModel', 'nemo_version': '1.21.0', 'decoding': {'strategy': 'greedy', 'preserve_alignments': None, 'compute_timestamps': None, 'word_seperator': ' ', 'ctc_timestamp_type': 'all', 'batch_dim_index': 0, 'greedy': {'preserve_alignments': False, 'compute_timestamps': False, 'preserve_frame_confidence': False, 'confidence_measure_cfg': {'name': 'entropy', 'entropy_type': 'tsallis', 'alpha': 0.33, 'entropy_norm': 'exp', 'temperature': 'DEPRECATED'}, 'confidence_method_cfg': 'DEPRECATED'}, 'beam': {'beam_size': 4, 'search_type': 'default', 'preserve_alignments': False, 'compute_timestamps': False, 'return_best_hypothesis': True, 'beam_alpha': 1.0, 'beam_beta': 0.0, 'kenlm_path': None, 'flashlight_cfg': {'lexicon_path': None, 'boost_path': None, 'beam_size_token': 16, 'beam_threshold': 20.0, 'unk_weight': -inf, 'sil_weight': 0.0}, 'pyctcdecode_cfg': {'beam_prune_logp': -10.0, 'token_min_logp': -5.0, 'prune_history': False, 'hotwords': None, 'hotword_weight': 10.0}}, 'confidence_cfg': {'preserve_frame_confidence': False, 'preserve_token_confidence': False, 'preserve_word_confidence': False, 'exclude_blank': True, 'aggregation': 'min', 'measure_cfg': {'name': 'entropy', 'entropy_type': 'tsallis', 'alpha': 0.33, 'entropy_norm': 'exp', 'temperature': 'DEPRECATED'}, 'method_cfg': 'DEPRECATED'}, 'temperature': 1.0}}\n"
     ]
    }
   ],
   "source": [
    "print(asr_model._cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  accelerator = 'gpu'\n",
    "else:\n",
    "  accelerator = 'gpu'\n",
    "\n",
    "EPOCHS = 20  # 100 epochs would provide better results\n",
    "\n",
    "trainer = pl.Trainer(devices=1,\n",
    "                      accelerator=accelerator,\n",
    "                      max_epochs=EPOCHS,\n",
    "                      enable_checkpointing=False,\n",
    "                      logger=False,\n",
    "                      limit_val_batches = 1.0,\n",
    "                      check_val_every_n_epoch = 1,\n",
    "                      val_check_interval = 1.0)\n",
    "\n",
    "# Setup model with the trainer\n",
    "asr_model.set_trainer(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-06-12 16:46:16 exp_manager:386] Experiments will be logged at C:\\Users\\vdovichev\\Documents\\proj1-STT\\FineTune\\nemo_experiments\\test2\\2024-06-12_16-46-16\n",
      "[NeMo I 2024-06-12 16:46:16 exp_manager:825] TensorboardLogger has been set up\n"
     ]
    }
   ],
   "source": [
    "from nemo.utils import exp_manager\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# Environment variable generally used for multi-node multi-gpu training.\n",
    "# In notebook environments, this flag is unnecessary and can cause logs of multiple training runs to overwrite each other.\n",
    "os.environ.pop('NEMO_EXPM_VERSION', None)\n",
    "\n",
    "config = exp_manager.ExpManagerConfig(\n",
    "    exp_dir=\"C:\\\\Users\\\\vdovichev\\\\Documents\\\\proj1-STT\\\\FineTune\\\\nemo_experiments\\\\\",\n",
    "    name=f\"test2\",\n",
    "    create_tensorboard_logger = True,\n",
    "    create_checkpoint_callback = True,\n",
    "    checkpoint_callback_params=exp_manager.CallbackParams(\n",
    "        monitor=\"val_wer\",\n",
    "        mode=\"min\",\n",
    "        always_save_nemo=True,\n",
    "        save_best_model=True,\n",
    "    ),\n",
    "    create_wandb_logger = False,\n",
    "    wandb_logger_kwargs={\n",
    "        \"name\": None,\n",
    "        \"project\": None,\n",
    "    },\n",
    ")\n",
    "\n",
    "config = OmegaConf.structured(config)\n",
    "\n",
    "logdir = exp_manager.exp_manager(trainer, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir \"C:\\\\Users\\\\vdovichev\\\\Documents\\\\proj1-STT\\\\FineTune\\\\nemo_experiments\\\\test2\\\\\" --port 8888"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 684/684 [00:24<00:00, 27.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        global_step        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           18.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    12.039067268371582     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_wer          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.25759127736091614    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       global_step       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          18.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   12.039067268371582    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_wer         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.25759127736091614   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'global_step': 18.0,\n",
       "  'val_loss': 12.039067268371582,\n",
       "  'val_wer': 0.25759127736091614}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(asr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-06-12 16:46:53 modelPT:728] Optimizer config = Novograd (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.9, 0.98]\n",
      "        eps: 1e-08\n",
      "        grad_averaging: False\n",
      "        lr: 0.005\n",
      "        weight_decay: 0.001\n",
      "    )\n",
      "[NeMo I 2024-06-12 16:46:53 lr_scheduler:910] Scheduler \"<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x0000027491663C10>\" \n",
      "    will be used during training (effective maximum steps = 596520) - \n",
      "    Parameters : \n",
      "    (warmup_steps: 10000\n",
      "    warmup_ratio: null\n",
      "    min_lr: 0.0005\n",
      "    last_epoch: -1\n",
      "    max_steps: 596520\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name              | Type                              | Params\n",
      "------------------------------------------------------------------------\n",
      "0 | preprocessor      | AudioToMelSpectrogramPreprocessor | 0     \n",
      "1 | encoder           | ConvASREncoder                    | 18.9 M\n",
      "2 | decoder           | ConvASRDecoder                    | 34.9 K\n",
      "3 | loss              | CTCLoss                           | 0     \n",
      "4 | spec_augmentation | SpectrogramAugmentation           | 0     \n",
      "5 | _wer              | WER                               | 0     \n",
      "------------------------------------------------------------------------\n",
      "18.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "18.9 M    Total params\n",
      "75.718    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-06-12 16:46:53 nemo_logging:349] c:\\Users\\vdovichev\\anaconda3\\envs\\nemo\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:438: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "      rank_zero_warn(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-06-12 16:46:54 nemo_logging:349] c:\\Users\\vdovichev\\anaconda3\\envs\\nemo\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:438: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "      rank_zero_warn(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 0it [00:00, ?it/s][NeMo I 2024-06-12 16:46:54 preemption:56] Preemption requires torch distributed to be initialized, disabling preemption\n",
      "Epoch 0:   0%|          | 18/7457 [00:10<1:12:10,  1.72it/s, v_num=6-16, train_step_timing in s=0.267]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-06-12 16:47:05 nemo_logging:349] c:\\Users\\vdovichev\\anaconda3\\envs\\nemo\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:53: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "      rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "trainer.fit(asr_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
